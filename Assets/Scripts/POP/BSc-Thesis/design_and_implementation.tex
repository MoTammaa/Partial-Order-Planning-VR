\chapter{Design and Implementation}
\label{chap:design_and_implementation}

In this chapter, we will discuss the design and implementation of the \ac{POP} algorithm, the design of the Virtual Environment  and the Unity components that were used to visualize the \ac{POP} algorithm. The chapter will also discuss the design of the user interface and the interaction techniques that were used in the \ac{VR} game.

\section[POP Algorithm]{\ac{POP} Algorithm} \label{sec:pop_algorithm_design}

This section will discuss some of the design decisions that were made during the implementation of the \ac{POP} algorithm. It will include an overview of the implemented algorithms that were used beside the \ac{POP} algorithm. In addition, it will discuss the data structures that were used to represent the planning domain and the planning problem.

\subsection{Nondeterministic Achievers \& Threat Search} \label {subsec:nondeterministic_achievers_threat_search}
\acf{POP} needs to be able to handle some form of nondeterminism in the planning domain. This is because the planner needs
to be able to handle situations where there are multiple ways to achieve a precondition
of an action. Nondeterminism is a concept that is used in computer science to describe the occurrence of events without a predictable outcome, where multiple outcomes are possible from a given state. In the context of planning, nondeterminism is used to describe the situation where there are multiple ways to achieve a precondition of an action, for example.
This cannot be achieved in practice without trying to search all possible ways of the choices that can be made.
So, to model nondeterminism in the planning domain, we need to use some form of graph search algorithm to search for all possible ways to achieve a precondition of an action efficiently. In this project, multiple graph search algorithms were implemented to handle nondeterminism in the planning domain. These algorithms are \ac{A*} Search, \ac{BFS}, and \ac{DLS} which is a variation of \ac{DFS}. All of these algorithms are discussed in detail in the following sections.


\subsection{Graph Search Algorithms} \label{subsec:graph_search_algorithms}
Graph search algorithms are widely used in computer science to solve problems that can be represented as graphs. They have many applications in various fields such as artificial intelligence, computer graphics, and computer vision. In this project, graph search algorithms were used to solve the problem of nondeterminism in the planning domain.
The following graph search algorithms were implemented in the project:
\begin{itemize}

    \item \textbf{\acf{A*} Search Algorithm} \label{subsubsec:a_star} \\
          \ac{A*} Search is a graph search \& traversal algorithm that is widely used in computer science due to its efficiency, optimality, and completeness. It is an informed search algorithm that uses a heuristic function to estimate the cost of reaching the goal from a given state. The heuristic function is used to guide the search towards the goal state by selecting the most promising nodes to explore. \ac{A*} Search is an extension of Dijkstra's algorithm that uses a heuristic function to estimate the cost of reaching the goal from a given state\cite{AStarAlgorithm}. \ac{A*} is a Best First Search algorithm that uses a priority queue to store the nodes to be explored. The priority queue is ordered based on a cost function that combines the cost of reaching the node from the start state and the heuristic estimate of the cost of reaching the goal from the node. The cost function is defined as $f(n) = g(n) + h(n)$, where $g(n)$ is the cost of reaching the node from the start state and $h(n)$ is the heuristic estimate of the cost of reaching the goal from the node. The algorithm selects the node with the lowest $f$ value from the priority queue and explores its neighbors until the goal is reached. The algorithm is guaranteed to find the optimal solution if the heuristic function is admissible, i.e., it never overestimates the cost of reaching the goal from a given state. The algorithm is also complete if the search space is finite and the heuristic function is consistent.

          In this project, $g(n)$ is the path (level) cost from the root node to the current node, and $h(n)$ heuristic was chosen to be the number of unsatisfied preconditions, i.e., the count of pairs in the $agenda$ discussed in section {\ref{subsec:pop_algorithm}}.

    \item \textbf{\acf{DLS} Search Algorithm} \label{subsubsec:dls}\\
          First, let's discuss the \ac{DFS} algorithm.
          \ac{DFS} is an uninformed search algorithm that is widely used in computer science to explore a graph or tree data structure. It is a depth-first traversal algorithm that explores the nodes deep in the graph before exploring the nodes at the same level. The algorithm starts at the root node and explores the nodes along each branch before backtracking to explore the other branches. The algorithm uses a stack data structure to store the nodes to be explored. The algorithm is not guaranteed to find the optimal solution, but it is complete if the search space is finite. The algorithm is also efficient in terms of memory usage as it only needs to store the nodes along the current path. However, the algorithm can get stuck in infinite loops if the graph contains an infinite deep path. To avoid this problem, a depth limit can be imposed on the search to limit the depth of the search tree. This is known as the \acf{DLS} algorithm. The algorithm is similar to \ac{DFS} but with an additional depth limit parameter that specifies the maximum depth of the search tree. The algorithm stops exploring a branch when the depth limit is reached and backtracks to explore other branches. The algorithm is complete if the depth limit is greater than the depth of the optimal solution. The algorithm is also efficient in terms of memory usage. In this project, \ac{DLS} was also provided as an option to be used in the \ac{POP} algorithm.

    \item \textbf{\acf{BFS} Search Algorithm} \label{subsubsec:bfs}\\
          \ac{BFS} is an uninformed search algorithm that is widely used to explore a graph or tree data structure. It is a breadth-first traversal algorithm, meaning that it explores the nodes at the same level before exploring the nodes at the next level. The algorithm starts at the root node and explores the nodes at the same level before moving to the next level. The algorithm uses a queue data structure to store the nodes to be explored. The algorithm is guaranteed to find a solution if one exist, even if the graph is infinite. However, the algorithm is not guaranteed to always find the optimal solution. The algorithm is also inefficient in terms of memory usage as it needs to store all the nodes at the current level. In this project, \ac{BFS} was also provided as an option to be used in the \ac{POP} algorithm.

\end{itemize}

\subsection{Unification Algorithm} \label{subsec:unification_algorithm}
Finding the \acf{MGU} of two terms is a crucial step in the \ac{POP} algorithm. The \ac{MGU} is used to unify two terms by finding a substitution that makes the two terms equal. The \ac{MGU} is the most general substitution that can be applied to the two terms to make them equal.
For example, consider the following terms: $P(x, B)$ and $P(A, y)$. The \ac{MGU} of these two terms is $\{x/A, y/B\}$, which means that the terms can be unified by substituting $A$ for $x$ and $B$ for $y$ to make them equal to $P(A, B)$.
The \ac{MGU} is used to unify the preconditions of an action with the current state of the world to determine if the action can be applied. The \ac{MGU} is also used to unify the effects of an action that can be used, for example, to detect threats in the partial plan.

In this project, the \ac{MGU} algorithm was implemented using a variation of the unification algorithm discussed in Russell and Norvig's book in Chapter 9 \cite{RN2009_Ch.9}, and taken from the lecture slides of the course \textit{Introduction to Artificial Intelligence} by Prof. Haythem Ismail \cite{Ismail2023}.
There is a convention used in the algorithm implementation: the variables are represented as strings starting with a lowercase letter, and the constants are represented as strings starting with an uppercase letter.
The algorithm described in \autoref{alg:unification_algorithm} has three main functions: UNIFY, UNIFY1, and UNIFYVAR. The UNIFY function takes two exrpressions as input, listifies them, and then calls the UNIFY1 function with the two listified expressions and an empty substitution set. An example of listifying an expression is converting the expression $P(x, f(y,z))$ to the list $[P, x, [f, y, z]]$.
\begin{algorithm}[H]
    \caption{Unification Algorithm}
    \begin{algorithmic}[1]
        \label{alg:unification_algorithm}
        \STATE \textbf{function} UNIFY($E1, E2$) :
        \RETURN UNIFY1(LISTIFY($E1$), LISTIFY($E2$), $\{\}$);
        \STATE
        --------------------------------------------------------------------------------------------------------
        \STATE
        \STATE \textbf{function} UNIFY1($E1, E2, \mu$) :
        \IF{$\mu = \text{fail}$}
        \RETURN fail
        \ENDIF
        \IF{$E1 = E2$}
        \RETURN $\mu$
        \ENDIF
        \IF{VAR?($E1$)}
        \RETURN UNIFYVAR($E1, E2, \mu$)\ENDIF
        \IF{VAR?($E2$)}
        \RETURN UNIFYVAR($E2, E1, \mu$)
        \ENDIF
        \IF{ATOM?($E1$) or ATOM?($E2$)}
        \RETURN fail
        \ENDIF
        \IF{LENGTH($E1$) != LENGTH($E2$)}
        \RETURN fail
        \ENDIF
        \RETURN UNIFY1(REST($E1$), REST($E2$), UNIFY1(FIRST($E1$), FIRST($E2$), $\mu$))
        \STATE
        --------------------------------------------------------------------------------------------------------
        \STATE
        \STATE \textbf{function} UNIFYVAR($x, e, \mu$) :
        \IF{$t/x \in \mu$ and $t \neq x$}
        \RETURN UNIFY1($t, e, \mu$)
        \ENDIF
        \STATE $t = \text{SUBST}(\mu, e)$
        \IF{$x$ occurs in $t$}
        \RETURN fail
        \ELSE
        \RETURN $\mu \circ \{t/x\}$
        \ENDIF
    \end{algorithmic}
\end{algorithm}
The UNIFY1 function takes two listified expressions and a substitution set as input and returns the most general unifier of the two expressions. The UNIFYVAR function takes a variable, an expression, and a substitution set as input and returns the most general unifier of the variable and the expression. The main algorithm starts in line 6 by checking if the substitution set is a failure, in which it returns a failure. Then, it checks if the two expressions are equal, in which it returns the curernt substitution set. Then, it checks if $E1$ or $E2$ is a variable, in which it calls the UNIFYVAR function with the first parameter being the variable and the second parameter being the expression. Then, it checks if $E1$ or $E2$ is an atom, in which it returns a failure in line 19. The reason for this is that after making sure that neither $E1$ or $E2$ are variables, and they are not equal, then they must be different atoms, and thus cannot be unified. Then, it checks if the length of $E1$ is not equal to the length of $E2$, in which it returns a failure in line 22, as we cannot unify two expressions with different lengths, like $P(x)$ and $P(x, y)$. Finally, it calls the UNIFY1 function recursively with the rest of the two expressions and the unification of the first elements of the two expressions.

The UNIFYVAR function starts by checking if the variable $x$ is already in the substitution set and bound to a term $t$ that is not equal to $x$, in which it calls the UNIFY1 function with the term $t$ and the input expression $e$. If the variable $x$ is not in the substitution set, then it substitutes every term in the expression $e$ with the substitution set $\mu$. Then, it checks if the variable $x$ occurs in the term $t$, in which it returns a failure, as we cannot unify a variable with an expression that contains the variable. If we had $x$ and $f(x)$, then the unification would fail, since it would result in an infinite recursion.
Otherwise, it returns the substitution set $\mu$ composite with the substitution $\{t/x\}$, which means that the term $t$ is substituted for the variable $x$ in the substitution set $\mu$.

\begin {figure}[h]
\dirtree{%
    .1 /POP.
    .2 controller.
    .3 POPController.cs.
    .2 engine.
    .3 Action.cs.
    .3 Agenda.cs.
    .3 BindingConstraints.cs.
    .3 CausalLink.cs.
    .3 Helpers.cs.
    .3 Literal.cs.
    .3 Operator.cs.
    .3 ParitalPlan.cs.
    .3 Planner.cs.
    .3 PlanningProblem.cs.
    .3 PriorityQ.cs.
}
\caption{Folder Structure of the POP Algorithm Engine}
\label{fig:pop_folder_structure}
\end{figure}


\subsection{Classes and Folder Structure} \label{subsec:class_diagram_and_folder_structure}
The \ac{POP} algorithm engine was implemented in C\#. The algorithm engine was divided into two main folders: the controller folder and the engine folder. The folder structure of the \ac{POP} algorithm engine is shown in \autoref{fig:pop_folder_structure}. The controller folder contains the \textbf{POPController} class, which is responsible for controlling the execution of the \ac{POP} algorithm for Unity. The engine folder contains all the classes that implement the \ac{POP} algorithm.
The class diagram of the \ac{POP} algorithm presented in \autoref{fig:pop} shows the main classes and their relationships in the \ac{POP} algorithm. In the following list, we will discuss the main classes, their responsibilities, how they are implemented, and what their structure is:
\begin{itemize}
    \item \textbf{PlanningProblem Class:} \\
          The \textbf{PlanningProblem} class is responsible for representing the planning problem, that is the only input to the \acl{POP} algorithm. The \textbf{PlanningProblem} class has the initial state, the goal state, and the set of operators as its members. The initial and goal states are represented as list of \textit{Literal} objects. The operators are represented as a list of \textit{Operator} objects. The class keeps hold of a list of \textit{Literals}, that is not given as an input, but is instantiated automatically once the planning problem is initialized, and it is used to keep track of the existing literals from the initial and goal states in addition to the literals in the preconditions and effects of the operators. This list is to assist the planner.

          The class has only one functional method, which is the \textbf{GetListOfAchievers()} method, that takes a \textit{literal} as input. The \textbf{GetListOfAchievers()} method is responsible for returning a list of operators that can achieve the input \textit{literal}. The \textbf{PlanningProblem} class also has some predefined problems that can be used to test the \ac{POP} algorithm and the \ac{VR} game. Among these problems are the \textit{Socks and Shoes problem}, the \textit{Milk, Bananas, and Cordless Drill problem}, the \textit{Groceries Buying problem} which is a simplified variation of the \textit{Milk, Bananas, and Cordless Drill problem}, and some other problems.

    \item \textbf{PartialPlan Class:} \\
          The \textbf{PartialPlan} class is responsible for representing the partial plan that is being constructed by the \ac{POP} algorithm. The \textbf{PartialPlan} class has a set of actions, a set of causal links, an instance of \textit{BindingConstraints} object, and a set of ordering constraints as its members. The class contains some helper functions that are used by the planner like the \textit{GetListOfActionAchievers()} method, and some others that are shown in the class diagram in \autoref{fig:pop}.

    \item \textbf{Planner Class:} \\
          It is the main class that has the core logic of the \ac{POP} algorithm. The \textbf{Planner} class has the Planning Problem, the Partial Plan, and the Agenda as its members. It also has variables counter array to keep track of the generated distinct variables. The following list will discuss the logic and flow of the \ac{POP} algorithm in the \textbf{Planner} class:
          \begin{itemize}
              \item The \textbf{Planner} class has the \textit{POP()} method that implements the \ac{POP} algorithm. The \textit{POP()} method is responsible for generating the plan by creating a priority queue or stack to store nodes to be used while searching. The \textit{POP()} method also has a loop that iterates over the priority queue or stack until the goal is reached or no nodes are left.
                    For each node, it checks if the node partial plan is not acyclic, if it is not, then it pops the node from the priority queue or stack and continues to the next node. If the partial plan is acyclic, then it checks if the node is a goal node, if it is, then it returns the plan. If the node is not a goal node, then it expands the node by applying the applicable actions to the node.

              \item The \textit{EXPAND()} method is responsible for expanding the node. It first chooses a pair of ($action$, $precondition$) from the $agenda$ based on some heuristic. The heuristic that I chose is to prioritize the pair with the precondition that has the least number of achievers, and this will be discussed in more details later in this section in the \textbf{Agenda} class implementation. Then, after selecting a pair of ($action$, $precondition$), the \textit{POP()} method gets the achievers by gathering the existing actions and new operators that can achieve this precondition, and for each achiever, it creates a new node applies this achiever to it and then adds this node to the main queue or stack.

              \item The \textbf{POP} method also has a helper method called \textit{ApplyAchiever()} that applies the achiever to the node. The \textit{ApplyAchiever()} method works by unifying the achiever's effect with the precondition of the action, then it adds the binding constraints to the partial plan of the node, and then it adds the causal link to the partial plan, as well as updating the ordering constraints with the achiever being ordered before the action with the precondition we are trying to achieve. It also checks whether the achiever is an existing action or a new action, so that if it is a new action, it adds it to the partial plan, update its ordering constraints to be between the \textit{Start} and \textit{Finish} actions, and adds the new action's preconditions to the agenda.

              \item After applying the achiever, the \textit{EXPAND()} method checks if the new node has threats before adding it to the priority queue or stack through a helper function, \textit{searchResolveThreats()}. The \textit{searchResolveThreats()} method is responsible for searching for threats in the partial plan and resolving them recursively until no threats are left. The \textit{searchResolveThreats()} method has the new added action achiever and the new causal link as inputs. It first starts to check if any of the causal links in the partial plan is threatened by the new action, and if it is, then it resolves the threat by trying promotion and demotion on new cloned nodes. If no other threats are found, then the new node is added to the priority queue or stack.

              \item The \textit{searchResolveThreats()} method also has a helper method called \textit{isThreat()} that checks if a causal link is threatened by an action. The \textit{isThreat()} method works by checking the conditions, discussed in the definition in Section \ref{def:threat}, to be a threat. The \textit{searchResolveThreats()} then checks if the new causal link input is threatened by any of the existing actions in the partial plan. If it is, then it follows the same steps as before to resolve the threat until there is no threats.

              \item No node is added to the main queue or stack until it passes all the checks and has no threats. All nodes outputted from the resolving of threats caused by the new action are then passed to checking whether the new causal link is threatened by any other action. After extensive testing, the planner was found to output wrong results of the all threats are not resolved recursively, or through an iterative approach of the recursive method, as this is the only stage where threats are checked and resolved.
          \end{itemize}

    \item \textbf{Agenda Class:} \\
          The \textbf{Agenda} class is responsible for representing the agenda that is used by the \ac{POP} algorithm. The agenda is a list of pairs of ($action$, $precondition$) that are used to keep track of the preconditions that need to be achieved. The class internally uses a priority queue to store the pairs of ($action$, $precondition$). The chosen heuristic is to prioritize the pair with the precondition that has the least number of achievers. This is because the precondition with the least number of achievers minimizes the branching factor of the search tree, which leads to a more efficient search \cite{RN2020_Ch.11}. This leads to detecting special cases faster, like the case where the precondition has only one achiever, in which the planner has no any other choice but to apply this achiever. The \textbf{Agenda} class has a custom comparer method that compares with the number of achievers of the preconditions. Finally, in the special case where the number of achievers is zero, the class throws an exception, indicating that there is no solution to the problem, and something is wrong with the input problem.

    \item \textbf{Operator Class:} \\
          The \textbf{Operator} class is responsible for representing the operators that are used in the planning domain. The operators has a name, a list of preconditions, a list of effects, and a string variables array to represent the unbonded variables and their relations in the effects and the preconditions of the operator.

    \item \textbf{Action Class:} \\
          The \textbf{Action} class is responsible for representing the actions that are used in the partial plan. The \textit{Operator} class is the superclass of this class. The \textbf{Action} class inherits the name, preconditions, effects, and variables array from the \textit{Operator} class. The class also has a method that checks if the action has conflicts in the effects or the preconditions. The conflicts that \textit{hasConflictingPreconditionsOrEffects()} method checks is of of that format: for example if $P(x), \lnot P(y) \in \text{preconditions}$, where $x$ and $y$ are bound to the same variable, and $P$ is the same predicate. This is a conflict because it is impossible for $x$ and $y$ to be the same variable and different at the same time.

    \item \textbf{Literal Class:} \\
          The \textbf{Literal} class is responsible for representing the literals, the conditions or the predicates that are used in the planning domain. The literals, in this project, are used to represent the preconditions, the effects, the initial state, and the goal state. The \textbf{Literal} class has a name, a list of arguments, and a boolean variable to represent the negation of the literal.

    \item \textbf{BindingConstraints Class:} \\
          The \textbf{BindingConstraints} class is responsible for representing the binding constraints that are used in the partial plan. The binding constraints contains all variables that are bound and equal (or not equal) to a constant term or another variable. As mentioned in \autoref{subsec:unification_algorithm}, there is a convention that variables are lowercase strings and constants are uppercase strings.
          In this class, the focus os on four main methods: \textit{SetEqual()}, \textit{SetNotEqual()}, \textit{getBoundEq()}, and \textit{getBoundNE()}. The \textit{SetEqual()} and \textit{SetNotEqual()} methods are used to set the constraints of the variables to be equal or not equal to each other. The \textit{getBoundEq()} and \textit{getBoundNE()} methods are used to get the variables that are bound equal or not equal to a term or another variable.

          In this project, for the \textbf{non-equality constraints}, I used a regular \textit{Hash Map} or \textit{Dictionary} data structure to store the constraints. The key of the \textit{Dictionary} is the variable, and the value is a list of variables not equal to the key variable. There is no relation between the variables in the list, and the list is not ordered.

          As for the \textbf{equality constraints} between the variables, I used a \textit{Disjoint Sets} representation. \textbf{Disjoint Sets} data structure is a set of elements partitioned into a number of non-overlapping subsets\cite{WikiDisjointSet}\cite{GeeksForGeeksDisjointSet}. The main reason for using a \textit{Disjoint Set} is that it is efficient in terms of time complexity. The implementation used in this project uses the \textit{Union-Find} algorithm to merge the sets and find the representative of the set, in other words, the constant term that is bound to the variable, or a variable if no constant term is bound to it. The \textit{Union-Find} implementation guarantees a time complexity of $O(\log n)$, where $n$ is the number of variables in the partial plan. This number may be large for some problems as the planner uses an incremented counter to generate new variables in action's parameters, as well as in the effects and preconditions of the actions. This number continues to grow as the planner decides to backtrack and generate new actions. Besides the time complexity, the \textit{Disjoint Set} was chosen because for all equal variables in a set, it will always have the same root, which is the representative of the set, which can make things easier to trace for humans.

          Using both data structures, the \textit{Dictionary} and the \textit{Disjoint Set}, the planner can easily check if there exists some logical contradiction in the binding constraints. For example, if there is a variable $x$ that is bound equal to a variable $y$, and $y$ is bound equal to a third variable $z$, then another constraint that makes $x$ not equal to $z$ is added direcly or indirectly, then the \textbf{BindingConstraints} class can easily detect this contradiction and stop the search.

    \item \textbf{CausalLink Class:} \\
          The \textbf{CausalLink} class is responsible for representing the causal links that are used in the partial plan. The exact definition of a causal link is discussed in the definition in Section \ref{def:causal_link}. The \textbf{CausalLink} class has a \textit{LinkCondition} of type \textit{Literal}, a \textit{Produceri} of type \textit{Action}, and a \textit{Consumerj} of type \textit{Action}.
          The \textit{Produceri} is the action that has the effect that is the \textit{LinkCondition}, and the \textit{Consumerj} is the action that has the precondition that is also the \textit{LinkCondition}.

    \item \textbf{PriorityQ Class:} \\
          The \textbf{PriorityQ} is a class taken from the Microsoft documentation and GitHub repository under the MIT license\cite{MicrosoftPQ}\cite{GitHubPQ}. The class is used to mimic the internal original implementation of the \textit{PriorityQueue} in C\#. The reason for creating this class is that the latest Unity \ac{LTS} version at the time of writing this thesis uses an older version of C\# language (C\# 9.0) that does not have the \textit{PriorityQueue} class.

\end{itemize}

% image of the pop class diagram (POP.png)
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{images/POP.png}
    \caption[Class Diagram of the POP Algorithm]{Class Diagram of the POP Algorithm}
    \label{fig:pop}
\end{figure}

% showing the results and outputs of running the code
\subsection{\ac{POP} Terminal Output} \label{subsec:pop_output}
